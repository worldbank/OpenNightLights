
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Introduction to remote sensing (20 min) &#8212; Open Nighttime Lights</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Introduction to nighttime light data (20 min)" href="mod1_2_introduction_to_nighttime_light_data.html" />
    <link rel="prev" title="Welcome" href="../welcome.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/wb_logo.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Open Nighttime Lights</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../welcome.html">
   Welcome
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 1 Introduction to remote sensing
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Introduction to remote sensing (20 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod1_2_introduction_to_nighttime_light_data.html">
   2. Introduction to nighttime light data (20 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 2 Introduction to open data and tools
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_1_data_overview.html">
   1. Data overview (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_2_getting_started_with_Python.html">
   2. Getting started with Python (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_3_introduction_to_Jupyter_notebooks.html">
   3. Introduction to Jupyter notebooks (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_4_introduction_to_GEE.html">
   4. Introduction to Google Earth Engine (GEE) (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_5_GEE_PythonAPI_and_geemap.html">
   5. GEE Python API and geemap (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_6_practical_exercise-image_visualization.html">
   6. Practical exercise: image visualization (10 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 3 Basic operations on raster files
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_1_DMSP-OLS_annual_composites.html">
   1. DMSP-OLS annual composites in Google Earth Engine (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_2_image_clipping_with_VIIRS.html">
   2. Image clipping with VIIRS-DNB (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_3_conditional_operations.html">
   3. Conditional operations (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_4_cell_statistics_band_math.html">
   4. Cell statistics and basic band math (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_5_expressions-PartA.html">
   5. Expressions (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_5_expressions-PartB.html">
   6. Expressions (continued)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_6_making_VIIRS_annual_composites.html">
   7. Making simple VIIRS-DNB annual composites (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_7_import_export_data.html">
   8. Importing and exporting data (5 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 4 Charting
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod4_1_time_series_charts.html">
   1. Time Series Charts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod4_2_histograms.html">
   2. Histograms
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 5 Data analysis and intercalibration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_1_DMSP-OLS_intercalibration.html">
   1. DMSP-OLS intercalibration (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_2_rate_of_change.html">
   2. Calculate rate of change (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_3_vector_and_raster_data.html">
   3. Working with vector and raster data (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_4_comparing_cities.html">
   4. Comparing cities (5 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 6 Exercise in data fusion for image classification
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_0_overview.html">
   1. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_1_framing_the_analysis.html">
   2. Framing the analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_2_supervised_learning_img_classification.html">
   3. Supervised learning and image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_3_intro_to_sentinel2.html">
   4. Intro to Sentinel-2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_4_intro_to_GHSL.html">
   5. Intro to Global Human Settlement Layer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_5_data_fusion.html">
   6. Data fusion: Sentinel-2, VIIRS-DNB, GHSL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_6_RF_classifier.html">
   7. Random Forest Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_7_final_analysis.html">
   8. Statistical inference
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  World Bank - Light Every Night AWS data archive
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../wb-light-every-night-readme.html">
   World Bank - Light Every Night
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Applications of nighttime lights
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../estimating-electricity-with-viirs.html">
   High Resolution Electricity Access (HREA) Indicators
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/tutorials/mod1_1_introduction_to_remote_sensing.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-remote-sensing">
   1.1. What is remote sensing?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#passive-and-active-sensors">
     1.1.1. Passive and Active Sensors
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#passive-remote-sensing">
       1.1.1.1. Passive remote sensing
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spatial-spectral-and-temporal-resolutions-in-remote-sensing">
   1.2. Spatial, spectral and temporal resolutions in remote sensing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spatial-resolution">
     1.2.1. Spatial resolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spectral-resolution">
     1.2.2. Spectral resolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#temporal-resolution">
     1.2.3. Temporal resolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trade-offs-in-remote-sensing-resolution">
     1.2.4. Trade-offs in remote sensing resolution:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications-of-remotely-sensed-derived-data-in-socio-economic-research">
   1.3. Applications of remotely-sensed derived data in socio-economic research
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   1.4. Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   1.5. References:
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-to-remote-sensing-20-min">
<h1><span class="section-number">1. </span>Introduction to remote sensing (20 min)<a class="headerlink" href="#introduction-to-remote-sensing-20-min" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-is-remote-sensing">
<h2><span class="section-number">1.1. </span>What is remote sensing?<a class="headerlink" href="#what-is-remote-sensing" title="Permalink to this headline">¶</a></h2>
<div class="alert alert-info">
<b>Remote sensing</b> is the science of identifying, observing, collecting and measuring objects without coming into direct contact with them.
</div>
<p>This can be accomplished through many devices that carry sensors and capture the characteristics of Earth remotely.</p>
<div class="figure align-default" id="remote-sensing">
<img alt="../_images/mod1-remote_sensing.png" src="../_images/mod1-remote_sensing.png" />
<p class="caption"><span class="caption-number">Fig. 1.1 </span><span class="caption-text">Remote sensing<br>
Source: <a class="bibtex reference internal" href="#nasa-goddard-2017" id="id1">[Cen17]</a></span><a class="headerlink" href="#remote-sensing" title="Permalink to this image">¶</a></p>
</div>
<p>Sensors on board satellites also record the electromagnetic energy that is reflected or emitted from objects on Earth.</p>
<div class="section" id="passive-and-active-sensors">
<h3><span class="section-number">1.1.1. </span>Passive and Active Sensors<a class="headerlink" href="#passive-and-active-sensors" title="Permalink to this headline">¶</a></h3>
<p>Sensors on board satellites can be classified into two main categories: Passive and Active.</p>
<div class="alert alert-info">
<b>Passive sensors</b> record the natural energy that is (naturally) reflected or emitted from the Earth's surface (e.g. sunlight, moonlight, city lights). 
</div>
<div class="alert alert-info">
<b>Active sensors</b> provide their own energy source for illumination (e.g. RADAR, LIDAR). 
</div>
<div class="section" id="passive-remote-sensing">
<h4><span class="section-number">1.1.1.1. </span>Passive remote sensing<a class="headerlink" href="#passive-remote-sensing" title="Permalink to this headline">¶</a></h4>
<p>The energy of the sun is composed of many kinds of radiation, some of which spans the visible part of the electromagnetic spectrum. Many instruments collect Red, Green, and Blue bands of the spectrum (R,G,B) to create natural color images.</p>
<p>Meaningful information is also contained in parts of the spectrum outside the range of human vision, including infrared (IR) and ulta-violet (UV).</p>
<div class="figure align-default" id="light-spectrum">
<img alt="../_images/mod1-light_spectrum.png" src="../_images/mod1-light_spectrum.png" />
<p class="caption"><span class="caption-number">Fig. 1.2 </span><span class="caption-text">Electromagnetic spectrum<br>
Source: <a class="bibtex reference internal" href="#hudedmani2017aso" id="id2">[HSJ17]</a></span><a class="headerlink" href="#light-spectrum" title="Permalink to this image">¶</a></p>
</div>
<p>The energy of the sun is absorbed or scattered by the atmosphere before it reaches earth.</p>
<p>In Remote Sensing analysis we aim to learn about objects on Earth through studying the radiation reflected and/or emitted by them.</p>
<div class="figure align-default" id="radiation">
<img alt="../_images/mod1-radiation.png" src="../_images/mod1-radiation.png" />
<p class="caption"><span class="caption-number">Fig. 1.3 </span><span class="caption-text">Reflected and emitted radiation<br>
Source: <a class="bibtex reference internal" href="#phdthesis" id="id3">[Dan15]</a></span><a class="headerlink" href="#radiation" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
</div>
<div class="section" id="spatial-spectral-and-temporal-resolutions-in-remote-sensing">
<h2><span class="section-number">1.2. </span>Spatial, spectral and temporal resolutions in remote sensing<a class="headerlink" href="#spatial-spectral-and-temporal-resolutions-in-remote-sensing" title="Permalink to this headline">¶</a></h2>
<p>Remote sensing instruments are characterized by different resolutions which will impact the decision as to which data to use and for which application (this is often referred to as “Fit-for-Purpose” technologies.</p>
<div class="section" id="spatial-resolution">
<h3><span class="section-number">1.2.1. </span>Spatial resolution<a class="headerlink" href="#spatial-resolution" title="Permalink to this headline">¶</a></h3>
<div class="alert alert-info">
<b>Spatial resolution</b> signifies the ground surface area that forms one pixel in the image. Sub-pixel objects can sometimes be resolved. 
</div>
<p>For example, dirt roads in Figures 1.4 are smaller than the 30 m Landsat pixels, but are still detected.</p>
<div class="figure align-default" id="landsat-7">
<img alt="../_images/mod1-landsat7.png" src="../_images/mod1-landsat7.png" />
<p class="caption"><span class="caption-number">Fig. 1.4 </span><span class="caption-text">Landsat-7 (30 m)</span><a class="headerlink" href="#landsat-7" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="sentinel2">
<img alt="../_images/mod1-sentinel2.png" src="../_images/mod1-sentinel2.png" />
<p class="caption"><span class="caption-number">Fig. 1.5 </span><span class="caption-text">Sentinel-2 (10 m)</span><a class="headerlink" href="#sentinel2" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="worldview">
<img alt="../_images/mod1-worldview.png" src="../_images/mod1-worldview.png" />
<p class="caption"><span class="caption-number">Fig. 1.6 </span><span class="caption-text">Worldview (50 cm)</span><a class="headerlink" href="#worldview" title="Permalink to this image">¶</a></p>
</div>
<p><strong>In this course:</strong> we will be working primarily with VIIRS-DNB and DMSP-OLS VNIR band data. Their spatial resolutions are approximately 750m and 2.7km , respectively.</p>
</div>
<div class="section" id="spectral-resolution">
<h3><span class="section-number">1.2.2. </span>Spectral resolution<a class="headerlink" href="#spectral-resolution" title="Permalink to this headline">¶</a></h3>
<div class="alert alert-info">
<b>Spectral resolution</b> signifies the number and width of spectral bands of the sensor. The higher the spectral resolution, the narrower the wavelength range for a given channel or band. 
</div>
<p>Typically, multispectral imagery refers to 3 to 10 bands, while hyperspectral imagery consists of hundreds or thousands of (narrower) bands (i.e. higher spectral resolution) (see Figure 1.7). Panchromatic is a single broad band that collects a wide range of wavelengths.</p>
<div class="figure align-default" id="multi-and-hyperspectral">
<img alt="../_images/mod1-hyperspectral.png" src="../_images/mod1-hyperspectral.png" />
<p class="caption"><span class="caption-number">Fig. 1.7 </span><span class="caption-text">Multispectral and hyperspectral imagery<br>
Source: <a class="bibtex reference internal" href="#gisgeography" id="id4">[Geo]</a></span><a class="headerlink" href="#multi-and-hyperspectral" title="Permalink to this image">¶</a></p>
</div>
<p><strong>In this course:</strong> we will be working with VIIRS-DNB and DMSP-OLS data, which have single panchromatic channels covering the wavelengths ranging from 500 to 900 nanometers.</p>
</div>
<div class="section" id="temporal-resolution">
<h3><span class="section-number">1.2.3. </span>Temporal resolution<a class="headerlink" href="#temporal-resolution" title="Permalink to this headline">¶</a></h3>
<div class="alert alert-info">
<b>Temporal resolution</b> refers to the repeat cycle, or frequency, with which a sensor revisits the same part of the Earth’s surface. You might hear this referred to as a satellite’s “revisit time.” 
</div>
<p>Generally speaking, the larger the swath width of a polar orbiting satellite, which you can think of as the width of the sensor’s field of view “cross-track” (or “left to right”) during an orbital pass , the higher the temporal resolution. This is because more of the earth is imaged in a single pass of the satellite.</p>
</div>
<div class="section" id="trade-offs-in-remote-sensing-resolution">
<h3><span class="section-number">1.2.4. </span>Trade-offs in remote sensing resolution:<a class="headerlink" href="#trade-offs-in-remote-sensing-resolution" title="Permalink to this headline">¶</a></h3>
<p>There is an inherent tradeoff between spatial, spectral and temporal resolutions. Typically, the higher the spatial resolution, the lower the spectral and the temporal resolution and the higher the temporal resolution, the lower the spatial and spectral resolutions (Figure 1.8).</p>
<div class="figure align-default" id="res-trade-offs">
<img alt="../_images/mod1-res_tradeoffs.png" src="../_images/mod1-res_tradeoffs.png" />
<p class="caption"><span class="caption-number">Fig. 1.8 </span><span class="caption-text">Trade-offs with spatial, spectral, and temporal resolution. The figure illustrates some of the tradeoffs in remotely sensed data.  For example, sensors that collect images in a high spatial resolution, will typically have lower spectral (less bands) and low temporal (less frequent re-visit) resolutions . On the other hand, the spatial and spectral resolution of sensors with a high temporal resolution (frequent revisit) will typically be lower than sensors that collect data in a low temporal resolution (less frequent revisit).<br>
Source: <a class="bibtex reference internal" href="#warner2009remote" id="id5">[WNF09]</a></span><a class="headerlink" href="#res-trade-offs" title="Permalink to this image">¶</a></p>
</div>
<p><strong>In this course:</strong> we will be using VIIRS-DNB and DMSP-OLS data. Both of these sensors image the same earth location at least once during the day and once during the night. We’re only interested in the nighttime pass, so our data can be considered to have a daily temporal resolution. However, as we will learn, it’s helpful to temporally aggregate data to account for noise or obstructions, such as cloud-cover, so our final analysis may end up using composite data that has time periods of up to a month or year.</p>
<div class="alert alert-success">
For detailed information on the VIIRS instrument, see the <a href="https://ncc.nesdis.noaa.gov/documents/documentation/viirs-users-guide-tech-report-142a-v1.3.pdf" class="alert-link">VIIRS Users Guide Technical Report</a>. For detailed information on DMSP-OLS, see [need citation].
</div>
</div>
</div>
<div class="section" id="applications-of-remotely-sensed-derived-data-in-socio-economic-research">
<h2><span class="section-number">1.3. </span>Applications of remotely-sensed derived data in socio-economic research<a class="headerlink" href="#applications-of-remotely-sensed-derived-data-in-socio-economic-research" title="Permalink to this headline">¶</a></h2>
<p>Remotely sensed observations are useful for a wide-range of economic research applications. Donaldson and Storeygard <a class="bibtex reference internal" href="#donaldson2016view" id="id6">[DS16]</a> outline some advantages of using remotely sensed data for economic studies:</p>
<p><strong>1. Improved accessibility to information difficult to obtain by other means:</strong></p>
<p>Remote sensing technologies can collect panel data at low marginal cost, repeatedly, and at large scale, providing proxies for a wide range of characteristics that are hard (or impossible) to measure by other means.</p>
<p><strong>2. High(er) spatial resolution:</strong></p>
<p>Remotely sensed data are typically available at a higher spatial resolution than other traditional data sources, for example, census data (which is available at the geographical unit of the census tract, the block group etc.).  Publicly available satellite imagery  used by economists provide measurements of every location on Earth and are not constrained to a specific scale in which the data was collected at or aggregated to.</p>
<p><strong>3. Wide geographic coverage and high temporal resolution:</strong></p>
<p>Data collected by satellites provide continuous and consistent observations of phenomena on Earth, regardless of the conditions on the ground (e.g. political strife or natural disasters), across borders, including inaccessible locations and with a uniform spatial sampling. Satellites have substantial temporal coverage, capturing every location on Earth on a daily or weekly basis. Some archives date back to  the 1970s.</p>
<p><strong>Nighttime lights are especially useful for a variety of socio-economic research and applications.</strong> There is a strong correlation between nighttime lights and Gross State Product (GSP) or Gross Domestic Product (GDP) measures, at the national, state and regional levels <a class="bibtex reference internal" href="#henderson2012measuring" id="id7">[HSW12]</a><a class="bibtex reference internal" href="#ghosh2010shedding" id="id8">[GLPDE+10]</a><a class="bibtex reference internal" href="#chen2011using" id="id9">[CN11]</a> or even at a more granular resolution. Thus, nighttime light observations can be used as a proxy for economic activity, especially over periods or regions where these data are not available or where the statistical systems are of low quality or when no recent population or economic censuses are available. Similarly, changes in nighttime light intensity can be used by economists as an additional measure of income growth when no other measures of income growth are available.</p>
<div class="figure align-default" id="gdpvsntl">
<img alt="../_images/mod1-elvidge-gdp-ntl.png" src="../_images/mod1-elvidge-gdp-ntl.png" />
<p class="caption"><span class="caption-number">Fig. 1.9 </span><span class="caption-text">Area of lighting versus GDP for 200 countries of the world. (from Elvidge et al., 2001) <a class="bibtex reference internal" href="#elvidge2001night" id="id10">[EIB+01]</a></span><a class="headerlink" href="#gdpvsntl" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Comparing nighttime lights and a series of socio-economic indicators:</strong>
Proville et al. (2017) <a class="bibtex reference internal" href="#proville2017night" id="id11">[PZAW17]</a> examined trends observed by DMSP-OLS in the period 1992-2013 and their correlation with a series of socio-economic indicators. {numref}proville They found the strongest correlations between nighttime lights, electricity consumption, CO2 emissions, and GDP, followed by population, CH4 emissions, N2O emissions, poverty and F-gas emissions.</p>
<div class="figure align-default" id="proville">
<img alt="../_images/mod1-proville.png" src="../_images/mod1-proville.png" />
<p class="caption"><span class="caption-number">Fig. 1.10 </span><span class="caption-text">Various socio-economic indicators vs DMSP-OLS nighttime lights measures<a class="bibtex reference internal" href="#proville2017night" id="id12">[PZAW17]</a></span><a class="headerlink" href="#proville" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Natural characteristics of Earth and nighttime lights:</strong>
Henderson et al. (2018) <a class="bibtex reference internal" href="#henderson2018global" id="id13">[HSSW18]</a> explored whether - and which - of the natural characteristics of Earth can explain the spatial distribution of economic activity worldwide, at least according to nighttime lights. The authors found that 24 physical geographic attributes can explain up to 47% of worldwide variation and up to 35% of the variation of lights within countries.</p>
<p>Among countries that developed early, agricultural variables incrementally explain over 6 times as much variation in lights as do trade variables. On the other hand, among late developing countries, the same ratio is only about 1.5, despite the fact that these countries are far more dependent on agriculture.</p>
</div>
<div class="section" id="summary">
<h2><span class="section-number">1.4. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Remote sensing instruments collect electromagnetic energy to map a variety of phenomena on the earth’s surface. These instruments typically trade between three categories of performance: spatial, spectral, and temporal. Remotely sensed imagery can reach all parts of the earth at a consistent resolution, and some archives span decades into the past. For this work we will focus on nighttime lights from the VIIRS-DNB and DMSP-OLS sensors. There is a long and significant body of research showing correlation between nighttime lights and a variety of useful socio-economic variables.</p>
</div>
<div class="section" id="references">
<h2><span class="section-number">1.5. </span>References:<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-tutorials/mod1_1_introduction_to_remote_sensing-0"><dl class="citation">
<dt class="bibtex label" id="nasa-goddard-2017"><span class="brackets"><a class="fn-backref" href="#id1">Cen17</a></span></dt>
<dd><p>NASA’s Goddard Space Flight Center. <em>Remotely Sensing Our Planet</em>. 2017. URL: <a class="reference external" href="https://svs.gsfc.nasa.gov/30892">https://svs.gsfc.nasa.gov/30892</a>.</p>
</dd>
<dt class="bibtex label" id="chen2011using"><span class="brackets"><a class="fn-backref" href="#id9">CN11</a></span></dt>
<dd><p>Xi Chen and William D Nordhaus. Using luminosity data as a proxy for economic statistics. <em>Proceedings of the National Academy of Sciences</em>, 108(21):8589–8594, 2011.</p>
</dd>
<dt class="bibtex label" id="phdthesis"><span class="brackets"><a class="fn-backref" href="#id3">Dan15</a></span></dt>
<dd><p>Saba Daneshgar. <em>Remote sensing observations for monitoring coastal zones, Volturno River mouth case study</em>. PhD thesis, Ghent University, 04 2015. <a class="reference external" href="https://doi.org/10.13140/RG.2.1.3806.9209">doi:10.13140/RG.2.1.3806.9209</a>.</p>
</dd>
<dt class="bibtex label" id="donaldson2016view"><span class="brackets"><a class="fn-backref" href="#id6">DS16</a></span></dt>
<dd><p>Dave Donaldson and Adam Storeygard. The view from above: applications of satellite data in economics. <em>Journal of Economic Perspectives</em>, 30(4):171–98, 2016.</p>
</dd>
<dt class="bibtex label" id="elvidge2001night"><span class="brackets"><a class="fn-backref" href="#id10">EIB+01</a></span></dt>
<dd><p>Christopher D Elvidge, Marc L Imhoff, Kimberly E Baugh, Vinita Ruth Hobson, Ingrid Nelson, Jeff Safran, John B Dietz, and Benjamin T Tuttle. Night-time lights of the world: 1994–1995. <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, 56(2):81–99, 2001.</p>
</dd>
<dt class="bibtex label" id="gisgeography"><span class="brackets"><a class="fn-backref" href="#id4">Geo</a></span></dt>
<dd><p>GIS Geography. <em>Multispectral vs Hyperspectral Imagery Explained - GIS Geography</em>. URL: <a class="reference external" href="https://gisgeography.com/multispectral-vs-hyperspectral-imagery-explained/">https://gisgeography.com/multispectral-vs-hyperspectral-imagery-explained/</a>.</p>
</dd>
<dt class="bibtex label" id="ghosh2010shedding"><span class="brackets"><a class="fn-backref" href="#id8">GLPDE+10</a></span></dt>
<dd><p>Tilottama Ghosh, Rebecca L Powell, Christopher D Elvidge, Kimberly E Baugh, Paul C Sutton, and Sharolyn Anderson. Shedding light on the global distribution of economic activity. <em>The Open Geography Journal</em>, 2010.</p>
</dd>
<dt class="bibtex label" id="henderson2018global"><span class="brackets"><a class="fn-backref" href="#id13">HSSW18</a></span></dt>
<dd><p>J Vernon Henderson, Tim Squires, Adam Storeygard, and David Weil. The global distribution of economic activity: nature, history, and the role of trade. <em>The Quarterly Journal of Economics</em>, 133(1):357–406, 2018.</p>
</dd>
<dt class="bibtex label" id="henderson2012measuring"><span class="brackets"><a class="fn-backref" href="#id7">HSW12</a></span></dt>
<dd><p>J Vernon Henderson, Adam Storeygard, and David N Weil. Measuring economic growth from outer space. <em>American economic review</em>, 102(2):994–1028, 2012.</p>
</dd>
<dt class="bibtex label" id="hudedmani2017aso"><span class="brackets"><a class="fn-backref" href="#id2">HSJ17</a></span></dt>
<dd><p>Mallikarjun. G. Hudedmani, Vishwanath.M Soppimath, and Chaitanya. K. Jambotkar. A study of materials for solar pv technology and challenges. In <em>A Study of Materials for Solar PV Technology and Challenges</em>. 2017.</p>
</dd>
<dt class="bibtex label" id="proville2017night"><span class="brackets">PZAW17</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id12">2</a>)</span></dt>
<dd><p>Jeremy Proville, Daniel Zavala-Araiza, and Gernot Wagner. Night-time lights: a global, long term look at links to socio-economic trends. <em>PloS one</em>, 12(3):e0174610, 2017.</p>
</dd>
<dt class="bibtex label" id="warner2009remote"><span class="brackets"><a class="fn-backref" href="#id5">WNF09</a></span></dt>
<dd><p>Timothy A Warner, M Duane Nellis, and Giles M Foody. Remote sensing scale and data selection issues. <em>The SAGE handbook of remote sensing</em>, 2:568, 2009.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../welcome.html" title="previous page">Welcome</a>
    <a class='right-next' id="next-link" href="mod1_2_introduction_to_nighttime_light_data.html" title="next page"><span class="section-number">2. </span>Introduction to nighttime light data (20 min)</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By World Bank<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>