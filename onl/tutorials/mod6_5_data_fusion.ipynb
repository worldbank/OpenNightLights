{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NLTGit/OpenNightLights-colab-mirror/blob/master/onl/tutorials/mod5_4_comparing_cities.ipynb) -->\n",
    "update colab:\n",
    "\n",
    "# Data fusion: Sentinel-2, VIIRS-DNB, GHSL\n",
    "\n",
    "**Note** that until this point we have been looking at the entire country of Nepal, but for simplicity sake -- and so we can work with the computing resource constraints of Google Earth Engine and local internet speeds, we will from this point focus our analysis on the Province of Bagmati, which contains the capital city Kathmandu.\n",
    "\n",
    "Now that we are familiar with the underlying data, we will integrate the the feature sourcs (Sentinel-2 and VIIRS-DNB) as well as add the GHSL data as layers.\n",
    "\n",
    "Let's again orient ourselves to the underlying data layers, including the masks we had created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9627ad99c346493a86dc3784189176ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[27.87388743003947, 85.41973735675019], controls=(WidgetControl(options=['position'], widget=HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geemap, ee\n",
    "\n",
    "try:\n",
    "        ee.Initialize()\n",
    "except Exception as e:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "\n",
    "# get our Nepal boundary\n",
    "roi = ee.FeatureCollection(\"FAO/GAUL/2015/level2\").filter(ee.Filter.eq('ADM2_NAME','Bagmati')).geometry()\n",
    "\n",
    "def se2mask(image):\n",
    "    quality_band = image.select('QA60')\n",
    "    cloudmask = 1 << 10\n",
    "    cirrusmask = 1 << 11\n",
    "    mask = quality_band.bitwiseAnd(cloudmask).eq(0) and (quality_band.bitwiseAnd(cirrusmask).eq(0))\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "    \n",
    "se2 = ee.ImageCollection('COPERNICUS/S2').filterDate(\n",
    "    \"2019-01-01\",\"2019-12-31\").filterBounds(roi).filter(\n",
    "    ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\",20)).map(se2mask).median().clip(roi)\n",
    "\n",
    "viirs = ee.Image(ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\"2019-01-01\",\"2019-12-31\").filterBounds(roi).median().select('avg_rad').clip(roi))\n",
    "\n",
    "ghsl = ee.ImageCollection('JRC/GHSL/P2016/SMOD_POP_GLOBE_V1').filter(ee.Filter.date('2015-01-01', '2015-12-31')).select('smod_code').median().clip(roi)\n",
    "\n",
    "ghsl = ghsl.gte(2)\n",
    "\n",
    "ghslVis= {\"palette\":['000000', 'ffffff']}\n",
    "se2Vis = {\"min\":0.0, \"max\":0.3,\"bands\": ['B4','B3','B2']}\n",
    "\n",
    "# initialize our map\n",
    "map1 = geemap.Map()\n",
    "map1.centerObject(roi, 9)\n",
    "map1.addLayer(se2, se2Vis, \"S2\")\n",
    "map1.addLayer(viirs, {}, \"VIIRS-DNB\")\n",
    "map1.addLayer(ghsl, ghslVis, \"GHSL\")\n",
    "map1.addLayerControl()\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Data exploration is a key part of any analysis. We won't dedicate too much time here but you would typically want to look at changes in these underlying datasets to spot any possible biases or inconsistencies (such as unexpected spikes or drops in the data over time or interesting spatial distributions). For now, we'll just take a sneak peak at the VIIRS to compare late 2016 with 2019. \n",
    "\n",
    "Note that we only look at the latter half of the year, because we do not have Sentinel-2 1-C data prior to July 2015 and we want to compare the same months of the year in 2015 as 2019 for both data sources.\n",
    "\n",
    "### VIIRS-DNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59b5cec4a4144b2a81da3864024ce45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[27.87388743003947, 85.41973735675019], controls=(WidgetControl(options=['position'], widget=HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viirs2015 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n",
    "    \"2015-07-01\",\"2015-12-31\").filterBounds(roi).median().select('avg_rad').clip(roi)\n",
    "viirs2019 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n",
    "    \"2019-07-01\",\"2019-12-31\").filterBounds(roi).median().select('avg_rad').clip(roi)\n",
    "\n",
    "viirs_15_tile = geemap.ee_tile_layer(viirs2015, {}, 'Jul-Dec 2015', opacity=0.75)\n",
    "viirs_19_tile = geemap.ee_tile_layer(viirs2019, {}, 'Jul-Dec 2019', opacity=0.75)\n",
    "\n",
    "# initialize our map\n",
    "map2 = geemap.Map()\n",
    "map2.centerObject(roi, 9)\n",
    "map2.split_map(left_layer=viirs_15_tile, right_layer=viirs_19_tile)\n",
    "map2.addLayerControl()\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some cleaning issues to be aware of in terms of the background noise, but it is clear that there are structure changes in nighttime lights that appear consistent with human settlement growth, particularly spreading out from Kathmandu along the road network.\n",
    "\n",
    "Let's try cleaning the data a bit (as we did in {doc}`mod3_4_cell_statistics_band_math` to get a clearer signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee93abc5e23943cf86deb85ee8a10347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[27.87388743003947, 85.41973735675019], controls=(WidgetControl(options=['position'], widget=HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu15 = viirs2015.reduceRegion(reducer=ee.Reducer.mean(),scale=500)\n",
    "std15 = viirs2015.reduceRegion(reducer=ee.Reducer.stdDev(),scale=500)\n",
    "mu19 = viirs2019.reduceRegion(reducer=ee.Reducer.mean(),scale=500)\n",
    "std19 = viirs2019.reduceRegion(reducer=ee.Reducer.stdDev(),scale=500)\n",
    "\n",
    "# we'll cast these to native ee Numbers using the ee.Number constructor\n",
    "mu15 = ee.Number(mu15.get('avg_rad'))\n",
    "std15 = ee.Number(std15.get('avg_rad'))\n",
    "mu19 = ee.Number(mu19.get('avg_rad'))\n",
    "std19 = ee.Number(std19.get('avg_rad'))\n",
    "\n",
    "viirs2015 = viirs2015.subtract(mu15).divide(std19)\n",
    "viirs2019 = viirs2019.subtract(mu15).divide(std19)\n",
    "\n",
    "viirs_15_tile = geemap.ee_tile_layer(viirs2015, {}, 'Jul-Dec 2015', opacity=0.75)\n",
    "viirs_19_tile = geemap.ee_tile_layer(viirs2019, {}, 'Jul-Dec 2019', opacity=0.75)\n",
    "\n",
    "# initialize our map\n",
    "map3 = geemap.Map()\n",
    "map3.centerObject(roi, 9)\n",
    "map3.split_map(left_layer=viirs_15_tile, right_layer=viirs_19_tile)\n",
    "map3.addLayerControl()\n",
    "map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a much clearer signal in terms of human activity and settlement areas. But we lost some information, which is potentially important if we want to pick up dimly lit areas that are transitioning from rural to low density.\n",
    "\n",
    "This is a very important aspect of data exploration: finding ways we may need to adjust the data. If our classifier fails to perform well, we may need to experiment with cleaning the data like this prior to training.\n",
    "\n",
    "Sometimes machine learning algorithms that are too senstive will \"learn\" noise too well and then perform badly on novel data, so cleaning data, which is by definition removing information, may help your classifier be more robust. We'll come back to this if we need to...for now let's move on.\n",
    "\n",
    "\n",
    "## Merging different data sources\n",
    "\n",
    "We are ultimately looking to classify land cover using both VIIRS-DNB and Sentinel-2, so we should merge them into a single file to make it easier to pass to our classifier.\n",
    "\n",
    "### Spatial resolution\n",
    "These are two different sources that have two different sets of attributes. In particular, VIIRS-DNB has a spatial resolution of about 750 meters whereas the Sentinel-2 MSI Level1-C data product we're using has a resolution that varies across the bands, from as low as 10 meters (including visible light bands B2, B3, B4) up to 60 meters. And our GHSL label has a resolution of 1 km. \n",
    "\n",
    "Our best approach with Google Earth Engine is to re-sample our data. We can:\n",
    "- downsample our higher-resolution data\n",
    "- disaggregate our lower resolution data to a smaller pixel size. **Note! this will not create a truly higher resolution image.** We cannot create visual information that is not present of course (unless we use some fance deep learning like Generative Adversarial Networks to do it artificially, but that's another topic...). This just disaggregates our \"larger\" size pixels into proportionally-valued smaller pixels.\n",
    "- we could re-sample all images to some separate resolution (say...500 meters)\n",
    "\n",
    "You may want err on the side of lower resolution if you're concerned with creating a robust classifier that can handle new data with versatility (i.e. not over-fit). Just as with the data cleaning above, you'll give it a bit less complex information to train on in order to make better predictions later.\n",
    "\n",
    "### Temporal resolution\n",
    "We also have to think about time. Our GHSL data is a rather static dataset generally time-stamped 2015 (although the underlying data is somewhat varied).\n",
    "\n",
    "We will create a dataset that is a single representation (in time) of all our data in 2015, i.e. a single composite image. Since we do have time dynamic data from Sentinel-2 and VIIRS-DNB we will reduce these data from the months in 2015 we have available: July through December. Recall that we do not have Sentinel-2 1-C data prior to July.\n",
    "\n",
    "## Creating our \"fused\" training dataset\n",
    "Let's first combine our VIIRS-DNB radiance band with our (all) our Sentinel-2 bands into a single Image object. For the Sentinel-2 bands, we'll choose the visible and near infra-red bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "se2bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7','B8','B8A']\n",
    "\n",
    "se2_2015 = ee.ImageCollection('COPERNICUS/S2').filterDate(\n",
    "    \"2015-07-01\",\"2015-12-31\").filterBounds(roi).filter(\n",
    "    ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\",20)).map(se2mask).median().clip(roi).select(se2bands)\n",
    "\n",
    "viirs2015 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n",
    "    \"2015-07-01\",\"2015-12-31\").filterBounds(roi).median().select('avg_rad').clip(roi)\n",
    "\n",
    "fused = se2_2015.addBands(viirs2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our GHSL, we'll want to extract points cooresponging with our \"built-up\" class that we can overlay over our feature data.\n",
    "\n",
    "We're choosing 1000 meters as our overall scaling factor for all data, a sample rate that matches the resolution of the GHSL native resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghslpoints = ghsl.sample(**{\"region\":roi, \"scale\":1000,\"seed\":0,'geometries':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10749"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghslpoints.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': {'geodesic': False,\n",
       "  'type': 'Point',\n",
       "  'coordinates': [85.67682022289937, 27.331242519336442]},\n",
       " 'id': '0',\n",
       " 'properties': {'smod_code': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghslpoints.first().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the \"property\" field name from GHSL: \"smod_code\". We'll use this to assign our training data labels (1 for built up, 0 for not built up after we binarized the \"degrees of urbanization\").\n",
    "\n",
    "Now we overlay these labels on our fused training image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all bands we're using in Sentinel-2 and VIIRS-DNB\n",
    "trainingbands = se2bands + ['avg_rad']\n",
    "\n",
    "training = fused.select(trainingbands).sampleRegions(collection=ghslpoints,\n",
    "                                                     properties=['smod_code'],\n",
    "                                                     scale=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': None,\n",
       " 'id': '0_0',\n",
       " 'properties': {'B2': 0.08789999783039093,\n",
       "  'B3': 0.0714000016450882,\n",
       "  'B4': 0.052299998700618744,\n",
       "  'B5': 0.0754999965429306,\n",
       "  'B6': 0.147599995136261,\n",
       "  'B7': 0.17309999465942383,\n",
       "  'B8': 0.17339999973773956,\n",
       "  'B8A': 0.19089999794960022,\n",
       "  'avg_rad': 0.1543983817100525,\n",
       "  'smod_code': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max': 1,\n",
       " 'mean': 0.18796029458853666,\n",
       " 'min': 0,\n",
       " 'sample_sd': 0.39071173874702697,\n",
       " 'sample_var': 0.15265566279472506,\n",
       " 'sum': 1174,\n",
       " 'sum_sq': 1174,\n",
       " 'total_count': 6246,\n",
       " 'total_sd': 0.39068046053869543,\n",
       " 'total_var': 0.15263122224672718,\n",
       " 'valid_count': 6246,\n",
       " 'weight_sum': 6246,\n",
       " 'weighted_sum': 1174}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.aggregate_stats('smod_code').getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imbalanced class:** We notice the mean value for our label (which is binary, 0 or 1) is 0.18, which indicates a fairly high ratio of non built up land (0) relative to built-up land (1). While this is expected behavior in such a real world dataset, class imbalance can be a challenge for classifiers. \n",
    "\n",
    "There are strategies to address this if our classifier performs badly, but we're just flagging this for now. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "If you see a theme here in how taking time to investigate your data can give you clues to improve your machine learning model later...you're catching on about a key aspect of data science!\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier training set can then be described as:\n",
    "- Training:\n",
    "    - Feature: VIIRS-DNB (\"avg_rad\", monthly median, July to Dec 2015)\n",
    "    - Feature: Sentinel-2 (select optical bands, monthly median, July to Dec 2015)\n",
    "    - Label: GHSL Settlement Grid (\"low\" and \"hi\" cluster areas, 2015)\n",
    " \n",
    "And our inference data, which we will create in the next exercise, will consist of a monthly time series that includes predicted \"built-up\" areas for each month from January 2016 to December 2020.\n",
    "\n",
    "- Inference:\n",
    "    - Feature: VIIRS-DNB (\"avg_rad\", monthly composites, January 2016 through December 2019)\n",
    "    - Feature: Sentinel-2 (select optical bands, monthly median, January 2016 through December 2019\n",
    "    - Labels: predicted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
